{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3094bfc4-342d-4df4-82ce-f54324ec5d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93c390ca-4d35-4881-990e-f278c85bb65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kashy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a88a069-e4df-436e-b00c-08da6b676224",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv('tmdb_5000_credits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b5f8da5-6b93-43d2-83f5-a1db28e48fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "budget                     0\n",
       "genres                     0\n",
       "homepage                3091\n",
       "id                         0\n",
       "keywords                   0\n",
       "original_language          0\n",
       "original_title             0\n",
       "overview                   3\n",
       "popularity                 0\n",
       "production_companies       0\n",
       "production_countries       0\n",
       "release_date               1\n",
       "revenue                    0\n",
       "runtime                    2\n",
       "spoken_languages           0\n",
       "status                     0\n",
       "tagline                  844\n",
       "title                      0\n",
       "vote_average               0\n",
       "vote_count                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ab29e49-c323-434b-a402-327bd92a4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.merge(credits, on='title')\n",
    "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew', 'popularity', 'vote_count', 'vote_average']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f3d9e55-23fa-4a08-a5f2-48df26ccc85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "508210b3-858f-4690-ba54-4d0b724912df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions to clean and extract data\n",
    "def get_name(obj):\n",
    "    name = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        name.append(i['name'])\n",
    "    return name\n",
    "\n",
    "def get_top_cast(obj):\n",
    "    counter = 0\n",
    "    name = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if counter != 3:\n",
    "            name.append(i['name'])\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "    return name\n",
    "\n",
    "def get_director_name(obj):\n",
    "    name = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if i['job'] == 'Director':\n",
    "            name.append(i['name'])\n",
    "            break\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7c74f55-76f9-49f6-9af1-0cc82c29988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply functions to clean the dataset\n",
    "movies['genres'] = movies['genres'].apply(get_name)\n",
    "movies['keywords'] = movies['keywords'].apply(get_name)\n",
    "movies['cast'] = movies['cast'].apply(get_top_cast)\n",
    "movies['crew'] = movies['crew'].apply(get_director_name)\n",
    "movies['overview'] = movies['overview'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a8fc4a5-e5c8-446d-a61c-a0d0f2f1507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean strings by removing spaces\n",
    "movies['genres'] = movies['genres'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "movies['keywords'] = movies['keywords'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "movies['cast'] = movies['cast'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "movies['crew'] = movies['crew'].apply(lambda x: [i.replace(\" \", \"\") for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f52f1fe2-cf12-4704-bc3a-f90c2779c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cda17a92-0cfe-492b-a747-25b70e0a9542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashy\\AppData\\Local\\Temp\\ipykernel_25244\\434461762.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x).lower())\n"
     ]
    }
   ],
   "source": [
    "new_df = movies[['movie_id', 'title', 'tags', 'popularity', 'vote_count', 'vote_average']]\n",
    "new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "921cc787-5f60-485a-9a7d-252a965f4d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashy\\AppData\\Local\\Temp\\ipykernel_25244\\688504635.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['tags'] = new_df['tags'].apply(lemmatize_tags)\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tags(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "new_df['tags'] = new_df['tags'].apply(lemmatize_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16266542-90af-4d98-a5c3-56deff7ece04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashy\\AppData\\Local\\Temp\\ipykernel_25244\\1018477640.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df[['popularity', 'runtime', 'vote_average']] = scaler.fit_transform(new_df[['popularity', 'vote_count', 'vote_average']])\n",
      "C:\\Users\\kashy\\AppData\\Local\\Temp\\ipykernel_25244\\1018477640.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df[['popularity', 'runtime', 'vote_average']] = scaler.fit_transform(new_df[['popularity', 'vote_count', 'vote_average']])\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF for textual data (tags)\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "tag_vectors = tfidf.fit_transform(new_df['tags']).toarray()\n",
    "\n",
    "# Normalize numerical features (popularity, vote_count, vote_average)\n",
    "scaler = MinMaxScaler()\n",
    "new_df[['popularity', 'vote_count', 'vote_average']] = scaler.fit_transform(new_df[['popularity', 'vote_count', 'vote_average']])\n",
    "\n",
    "TEXTUAL_WEIGHT = 0.7\n",
    "POPULARITY_WEIGHT = 0.1\n",
    "VOTE_COUNT_WEIGHT = 0.1\n",
    "VOTE_AVERAGE_WEIGHT = 0.1\n",
    "\n",
    "textual_similarity = cosine_similarity(tag_vectors)\n",
    "popularity_similarity = cosine_similarity(new_df[['popularity']])\n",
    "vote_count_similarity = cosine_similarity(new_df[['vote_count']])\n",
    "vote_average_similarity = cosine_similarity(new_df[['vote_average']])\n",
    "\n",
    "# Combine all similarities with weights\n",
    "combined_similarity = (TEXTUAL_WEIGHT * textual_similarity +\n",
    "                       POPULARITY_WEIGHT * popularity_similarity +\n",
    "                       VOTE_COUNT_WEIGHT * vote_count_similarity +\n",
    "                       VOTE_AVERAGE_WEIGHT * vote_average_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "309287af-02ab-46b7-8bbe-0e0e8e5daaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(new_df.to_dict(), open('movies_dict.pkl', 'wb'))\n",
    "pickle.dump(combined_similarity, open('similarity.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
